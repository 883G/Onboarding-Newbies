# 883 Group Onboarding - Newbies :baby_bottle:

Welcome to the 883 Group Onboarding for Newbies! This repository is your gateway to a structured 10-chapter program, designed to seamlessly integrate you into our dynamic Data Ops team. Dive into topics ranging from Hadoop Ecosystem to Spark, Kubernetes, and more.

## Chapter 00: Foundations of Data Operations and Customer Engagement in the 883 Group
- **[Day 00](./chapter_00/day_00.md):** Welcome & Introduction - Understand the onboarding process and the 883 Group's vision and mission :dart:
- **[Day 01](./chapter_00/day_01.md)** Introduction to Big Data - Core Concepts 
- **[Day 02](./chapter_00/day_02.md):** Customer Interaction and Insight into Data Operations & Data Lifecycle in the 883 Group
:bow_and_arrow:


## Chapter 01: Introduction to Hadoop Ecosystem
- **[Day 03](./chapter_01/day_03.md):**  Introduction to Data concept & Hadoop Ecosystem (Hadoop, HDFS, MapReduce, YARN, Hive, ZooKeeper):elephant:
- **[Day 04](./chapter_01/day_04.md):**  Introduction to Data concept & Hadoop Ecosystem (HBase, Spark, Kafka, Impala, Partitioning, Kerberos, Oozie):elephant::elephant:
- **[Final Exercise](./chapter_01/final_exercise_01.md):** Introduction to Data Ops Team and Hadoop Ecosystem concepts Q&A :question:
- **[Showcase](./chapter_01/showcase/showcase01.md):** In-Depth Exploration of Hadoop Ecosystem Component(s) :book:


## Chapter 02: Basic Docker & Testing & CI-CD
- **[Day 05](./chapter_02/day_05.md)** Mastering OOP and Design Principles with Test-Driven Development (TDD)
- **[Day 06](./chapter_02/day_06.md):**  Writing Clean Code
- **[Day 07](./chapter_02/day_07.md):** Embarking on the Docker Journey
- **[Exercise 01](./chapter_02/final_exercise_02.md):** Clean Code Refactoring 
- **[Exercise 02](./chapter_02/final_exercise_03.md):** Embracing DevOps: GitLab, Docker, and CI/CD Pipeline


## Chapter 03: DevOps in Openshift
- **[Day 08](https://883g.github.io/GO-TO-INTERNAL)** Openshift Fundamentals for Data Ops using "zero to hero" Openshift labs
- **[Day 09](https://883g.github.io/GO-TO-INTERNAL)** Helm for Kubernetes Package Management using "Hero to Master" Openshift labs 
- **[Day 10](https://883g.github.io/GO-TO-INTERNAL)**  Openshift "Best Practises"  Openshift labs
- **Showcase:** Present the advantages of Kubernetes in a data ops context and discuss Helm's role in managing Kubernetes applications.


## Chapter 04: Proficiency in Spark

- **[Day 11](./chapter_04/day_11.md)** Read the following chapters from the [Spark Book](https://github.com/hemant-rout/BigData/blob/master/Learning%20Spark%20%20Lightning-Fast%20Big%20Data%20Analysis%20.pdf)

### **Exercise:** Develop a Sample Spark Job
Hands-on experience is crucial for mastering Spark. We will guide you through the process of developing a sample Spark job using: [Spark's official documentation](https://spark.apache.org/docs/latest/)
    - Python programming languages for Spark job development.
    - Executing and validating the Spark job locally.

- **Showcase:** Present Best Practices for Optimizing Spark Jobs
Optimizing Spark jobs is essential for efficient data processing. During the showcase, we will discuss and demonstrate:

    - [Spark Performance Tuning](https://spark.apache.org/docs/latest/tuning.html)
    - Best practices for configuring Spark applications.
    - Strategies for handling large datasets and improving job performance.


## chapter 3: Mastering Apache Airflow for Workflow Orchestration

- **Chapter 4:** Mastering Apache Airflow for Workflow Orchestration
This chapter focuses on mastering Apache Airflow, an open-source platform to programmatically author, schedule, and monitor workflows. Topics covered include:

    - [Introduction to Apache Airflow](https://airflow.apache.org/)
    - Understanding the architecture and components of Airflow.
    - Exploring the Airflow web UI and CLI for workflow management.
    - Defining key concepts like DAGs, Operators, and Sensors in Airflow.

- **Exercise:** Create an Airflow DAG for Orchestrating a Data Workflow
In this hands-on exercise, you will learn to:

    - Design an Airflow DAG to represent a data workflow.
    - Use different Operators (e.g., PythonOperator, BashOperator) to define tasks within the DAG.
    - Schedule and execute the DAG to orchestrate the defined workflow.

- **Showcase:**  Explain Key Concepts of Airflow DAGs
During the showcase, we will dive deeper into Airflow DAGs, discussing:

    - [Airflow Concepts and Terminology](https://airflow.apache.org/docs/apache-airflow/stable/concepts/index.html)
    - DAG structure and its components.
    - Task dependencies and execution order.
    - Monitoring and logging capabilities in Airflow.


## chapter 5: Iceberg and Trino in Data Operations
- **Chapter 7:** Managing Data with Iceberg
- **Chapter 8:** Exploring Trino as a Query Engine
- **Exercise:** Implement Iceberg for data management and work with Trino for querying data efficiently - create mini parquet merager.
- **Showcase:** Showcase the benefits of using Iceberg for managing evolving datasets and discuss Trino's advantages as a query engine.

## chapter 6: Operators and Controllers in Kubernetes
- **Chapter 9:** Understanding Kubernetes Operators
- **Chapter 10:** Custom Controllers for Data Ops
- **Exercise:** Develop a custom Kubernetes controller to handle ConfigMap upgrades in given namespaces.
- **Showcase:** Explain the concept of Kubernetes operators and their role VS contorllers.

## chapter 7: Real-world Project Simulation
- **Chapter 11:** Simulating Real-world Data Ops Projects
- **Chapter 12:** Troubleshooting and Debugging Techniques
- **Exercise:**  Do [Final Exercise](FinalExercise.md) and present the solution.
- **Showcase:** Share insights gained from the simulation and discuss troubleshooting strategies.

## chapter 8: Best Practices and Spark Optimization
- **Chapter 13:** Best Practices and Spark Optimization in Spark metrics and Spark ui analysis
- **Chapter 14:** Performance Spark Optimization Strategies
- **Exercise:** Optimize a Spark job for better performance and efficiency.
- **Showcase:** Present the optimized Spark job and discuss the strategies employed for performance improvement.

## chapter 9: Advanced Airflow Concepts and Practical Implementation
- **Chapter 15:** Airflow Cluster Setup and Configuration
- **Chapter 16:** Writing Custom Airflow Operators
- **Exercise:** Set up an Airflow cluster and write a custom operator to interact with an external system.
- **Showcase:** Demonstrate the configured Airflow cluster and showcase the custom operator in action.

## chapter 10: Documentation and Knowledge Sharing
- **Chapter 17:** Importance of Documentation in Data Ops
- **Chapter 18:** Effective Knowledge Sharing within the Team
- **Exercise:** Create documentation for a sample project and present it to the team.
- **Showcase:** Lead a discussion on the significance of documentation and effective knowledge sharing practices.

## Continuous Learning and Specialized Tracks
- Encourage continuous learning in areas like cloud integration, security, and emerging technologies.
- Provide access to resources and support for team members to specialize in areas of interest.
