# Final Exercise 01 - Introduction to Hadoop Ecosystem - Q&A :question:

## Goals:
- Gain a foundational understanding of the Hadoop ecosystem.
- Explore key components and their roles in big data processing.
- Make connections between the Hadoop ecosystem and real-world use cases.
- Develop a high-level understanding of the Hadoop ecosystem and its role in big data processing.
- Familirize yourself with the Hadoop ecosystem and its role in big data processing.
- Start to work with time estimation and planning.
- Learn to ask questions and how to find the answers with deep understanding of the whole concept.

:warning: **Note:**
- Maybe this is the first time you need to answer questions with your own words, so take your time to read the instructions carefully and ask your mentor if you have any questions.
- Take time to think about the answers, don't just copy-paste from the internet.
- Try to differ between the important and less important information.

## Q&A and Discussion
- Open forum for questions, clarifications, and discussions with the mentor.
- Reflection on the day's learnings and exploration of potential project applications.

### Chapter 1: Introduction to Big Data and Hadoop

1.  What is Apache Hadoop?
2.  Can you name a few vendor-specific distributions of Hadoop?
3.  What are the three modes in which Hadoop can run?
4.  What is the primary role of the `hadoop-env.sh` configuration file?
5.  What purpose does the `core-site.xml` file serve?

### Chapter 2: Hadoop Distributed File System (HDFS)

6.  What is HDFS?
7.  What is the role of the NameNode in HDFS?
8.  What is a DataNode in HDFS?
9.  How does HDFS achieve fault tolerance?
10.  Can you explain rack awareness in HDFS?

### Chapter 3: MapReduce Programming Model

11.  What is MapReduce?
12.  What is the role of a Mapper in MapReduce?
13.  What is the role of a Reducer in MapReduce?
14.  What is meant by "Shuffling" in MapReduce?
15.  Can a MapReduce job have zero Reducers?

### Chapter 4: Hadoop YARN

16.  What is YARN?
17.  What are the main components of YARN?
18.  What is the Resource Manager in YARN?
19.  What is the role of the Node Manager in YARN?
20.  How does YARN provide fault tolerance?

### Chapter 5: Apache Hive

21.  What is Apache Hive?
22.  What is the Hive Metastore?
23.  What is HiveQL?
24.  What are partitions in Hive?
25.  Can you define SerDe in the context of Hive?

### Chapter 6: Apache ZooKeeper

26.  What is Apache ZooKeeper and what role does it play in a distributed environment?
27.  Can you explain the concept of znodes in ZooKeeper?
28.  How does ZooKeeper handle coordination and configuration management across distributed systems?
29.  What are ephemeral nodes and sequence nodes in ZooKeeper, and how are they used?
30.  How does ZooKeeper ensure data consistency and reliability across distributed nodes?

### Chapter 7: Apache HBase

31.  What is Apache HBase?
32.  What is a Row Key in HBase?
33.  What is a Column Family in HBase?
34.  How does HBase ensure data availability and fault tolerance?
35.  What is the role of ZooKeeper in an HBase environment?

### Chapter 8: Apache Kafka

36.  What is Apache Kafka?
37.  What are Topics in Kafka?
38.  What are Partitions in Kafka?
39.  What is the role of a Broker in Kafka?
40.  What is the difference between a Kafka Producer and a Consumer?

### Chapter 10: Apache Impala

41.  What is Apache Impala?
42.  What is an Impala Daemon?
43.  What is the role of a Catalog Service in Impala?
44.  What is the role of a Query Coordinator in Impala?
45.  What is the difference between Refresh and Invalidate in Impala?

### Chapter 11: Partitioning

46.  What is Partitioning in databases and data storage?
47.  What are some common partitioning criteria?
48.  What is a Partition Key?
49.  Can you explain Partition Pruning?
50.  How is datetime-based partitioning used in real-world scenarios?

### Chapter 12: Kerberos Authentication

51.  What is the primary purpose of the Key Distribution Center (KDC) in the Kerberos authentication system, and what are its two main components?
52.  How does the "kinit" command contribute to the Kerberos authentication process, and what does it allow users to obtain?
53.  Explain the concept of "Single Sign-On (SSO)" in the context of Kerberos authentication and its benefits for users.
54.  Why is the concept of "time sensitivity" important in Kerberos authentication, and how does it enhance security?
55.  In what real-world scenarios or use cases is Kerberos authentication commonly employed, and how does it contribute to security and ease of use in those contexts?

### Chapter 13: Oozie Workflow Scheduler

56.  What is Apache Oozie, and how does it facilitate job scheduling and workflow management in a Hadoop environment?
57.  Can you differentiate between an Oozie Workflow job and a Coordinator job? Provide an example of when you would use each.
58.  Describe the lifecycle of an Oozie job. What are the typical states an Oozie job can be in, and what are the implications of each state?
59.  How does Oozie support SLA (Service Level Agreement) monitoring, and why is it important in managing data processing jobs?
60.  What are the main components of an Oozie Workflow job, and what is the role of each component?

## SKILA :pinched_fingers: :boxing_glove:
- The mentors will ask you qustions from their experience, prepare yourself to answer them.

## Wrapping Up :hourglass_flowing_sand:
Discuss your answers with your mentor and seek feedback on your understanding of the Hadoop ecosystem. Reflect on the areas where you need to improve and make a plan to strengthen your knowledge in those areas. Tomorrow, you will have the opportunity to present your research findings to the team, so make sure to prepare your presentation and be ready to share your insights.

## Action Items :pencil:
- Review your answers and seek clarification on any concepts you're unsure about.
- Identify areas for deeper exploration and make a plan to enhance your understanding of the Hadoop ecosystem.
- Prepare your presentation for tomorrow's showcase and be ready to share your insights with the team.
- Start to work with time estimation and planning.
- Learn to ask questions and how to find the answers with deep understanding of the whole concept.
