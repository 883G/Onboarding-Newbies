# Day 15 - Basic Spark Topics :sparkles:

## Overview:
Today, you will get to know Spark's history, its capabilities, and the problems it aims to solve.
You will familiarize yourself with basic spark terminology and features that will help you get started in the Apache Spark ecosystem.
Familiarizing yourself with these topics is essential for building high-performance Spark applications and optimizing your data processing workflows.

## Goals:
- Explore basic Spark terminology and learn basic concepts.
- Dive deeper into Spark's core concepts and features.

:warning: **Note:**
- Advanced topics in Spark will help you optimize your Spark applications and gain a deeper insight into its inner workings.
- These topics are essential for building high-performance Spark applications.
- This chapter will cover the essential concepts of the Spark and you will have a Q&A session with your mentor to discuss what you have learned.
- To gain a deeper understanding of the concepts and how they are applied in real-world scenarios we'll provide you with key concepts and a brief explanation for each core concept. Your task is to delve deeper into each concept by researching them. 
- Utilize Google, YouTube, or any other reliable source to gather comprehensive information that helps you grasp each concept thoroughly. This preparation will equip you for a productive question-and-answer session with your mentor, where you'll be expected to discuss what you've learned.
- **Before you start**  take a look to the [Final Exercise](final_exercise_04.md) and try to understand what you need to do, so you can focus on the main concepts that you need to learn. don't waste your time on the concepts and details that you don't need to know.
- If you have any questions and have conflicts if you need to learn some concept or not, you should discuss it with your mentor.
- Read only chapters and subchapters that are listed here.
- The topics in the Book may not cover all of what you may be asked about during the final exercise. Research **additional** advanced topics by yourself!
- This books first covers the topics from an applicative point of view, and then dives into the infrastructural aspect of them.

Read the following chapters from the [Spark Book](https://tinyurl.com/ykb29t4f).

:bulb: The numbering of the chapters matches the numbering of the chapters in the book.
Focus only on the chapters/subchapters mentioned. 

## I. Gentle overview of Big Data and Spark
**Topics Covered:**
- What is Apache Spark?
- A Gentle Introduction to Spark
- A Tour of Spark's Toolset.

### What is Apache Spark?
- Apache Spark's philosophy.
- Context: the Big Data problem.
- History of Spark.

### A Gentle Introduction to Spark
- Spark's basic architecture.
- Spark's language APIs.
- Spark's APIs.
- Starting Spark.
- The SparkSession.
- DataFrames.
- Transformations.
- Actions.
- Spark UI.
- An end to end example.

### A Tour of Spark's Toolset
- Running production applications.
- Datasets: Type-Safe structured APIs.
- Lower level APIs.
- Spark's ecosystem and packages.

## **Wrapping Up:** :hourglass_flowing_sand:
**Congratulations on completing Day 15! You've delved into advanced Spark topics, which are crucial for optimizing and fine-tuning your Spark applications. Keep exploring and applying these concepts to excel in big data processing with Spark.**

Discuss with your mentor about the day's learnings and explore potential project applications. Reflect on the significance of advanced Spark topics and how you can apply these concepts in your big data processing endeavors.

**Discussion and Q&A:** :raising_hand:
  - Engage in a discussion with mentors and peers to share insights and experiences related to advanced Spark topics.
  - Ask questions and seek clarification on any challenging concepts.
  - Discuss real-world applications and implications of advanced Spark programming in big data processing workflows.

## **Action Items:**
- Identify areas for deeper exploration.
- Get recommendations on resources for further learning.
- Reflect on how you can integrate advanced Spark concepts into your current or future projects.

## **Recommended Articles and Videos:** :bulb:
- [Spark Memory Management](https://community.cloudera.com/t5/Community-Articles/Spark-Memory-Management/ta-p/317794#:~:text=Spark%20Memory%20is%20the%20memory,storage%20memory%20of%20this%20segment.) - A comprehensive guide to Spark memory management and optimization strategies.
- [Spark Perforence Boosting](https://towardsdatascience.com/apache-spark-performance-boosting-e072a3ec1179) - A guide to boosting performance in Apache Spark applications.
- [Best practices for caching in Spark SQL](https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34?_branch_match_id=1291428628002391767&_branch_referrer=H4sIAAAAAAAAA8soKSkottLXz8nMy9bLTU3JLM3VS87P1Q9LK7cILisqMypNAgBOSaAeIwAAAA%3D%3D) - A comprehensive guide to caching best practices in Spark SQL.
- [Spark Joins Tuning Part-1(Sort-Merge vs Broadcast)](https://medium.com/swlh/spark-joins-tuning-part-1-sort-merge-vs-broadcast-a98d82610cf0) - A detailed explanation of Spark join tuning techniques, including sort-merge and broadcast joins.
- [4 Tips To Write Scalable Apache Spark Code](https://pub.towardsai.net/4-tips-to-write-scalable-apache-spark-code-1c736e4d698e) - A guide to writing scalable Apache Spark code for efficient data processing.
- [Apache Spark Optimization Techniques and Tuning - Almog Gelber (Hebrew)](https://www.youtube.com/watch?v=BzVrPCIeXuY) - A video tutorial on Spark optimization techniques and tuning.
- [Apache Spark Optimization Techniques and Tuning](https://link.medium.com/ssMBzZ2u2ub) - A comprehensive guide to optimizing Spark applications for performance and efficiency.
- [Spark partitioning: the fine print](https://link.medium.com/N5FLo0Xu2ub) - A detailed explanation of Spark partitioning and its impact on application performance.
- [OPTIMIZATION IN SPARK : Data frame focused](https://link.medium.com/qU8KaZPu2ub) - A guide to optimizing Spark DataFrames for improved performance.
- [Spark partitioning: full control](https://link.medium.com/c6HaLDKu2ub) - A comprehensive tutorial on achieving full control over Spark partitioning for optimized data processing.
- [Apache Spark Memory Management](https://link.medium.com/Kp7ANdJu2ub) - An in-depth exploration of Spark's memory management and optimization strategies.
- [Understanding Apache Spark Shuffle](https://link.medium.com/bt6yuLHu2ub) - A detailed explanation of Spark's shuffle mechanism and its impact on application performance.
- [Spark Performance Tuning: Skewness Part 1](https://link.medium.com/75bcHwFu2ub) - A comprehensive guide to handling skewness in Spark applications for improved performance.
- [Understanding Apache Spark Hash-Shuffle](https://link.medium.com/Cbmrk0Du2ub) - A detailed explanation of Spark's hash shuffle mechanism and its impact on application performance.
- [Spark Performance Tuning: Skewness Part 2](https://link.medium.com/MJdZjhzu2ub) - A continuation of the guide to handling skewness in Spark applications for improved performance.
- [Apache Spark Core—Deep Dive—Proper Optimization Daniel Tomes Databricks](https://youtu.be/daXEp4HmS-E) - A deep dive into optimizing Apache Spark Core for performance and efficiency.
- [Deep Dive: Apache Spark Memory Management](https://youtu.be/dPHrykZL8Cg) - A comprehensive video tutorial on Apache Spark memory management and optimization.
- [Understanding Query Plans and Spark UIs - Xiao Li Databricks](https://youtu.be/YgQgJceojJY) - A detailed explanation of query plans and Spark UIs for performance optimization.
- [Optimizing Apache Spark SQL Joins: Spark Summit East talk by Vida Ha](https://youtu.be/fp53QhSfQcI) - A talk on optimizing Apache Spark SQL joins for improved performance.
- [Should I repartition? About Data Distribution in Spark SQL.](https://link.medium.com/eUomzhK0Pub) - A comprehensive guide to understanding data distribution in Spark SQL and its impact on performance.
- [Spark study notes: core concepts visualized](https://link.medium.com/B1S6b3I0Pub) - Visualized study notes on core concepts of Apache Spark.
- [Part 3: Cost Efficient Executor Configuration for Apache Spark](https://link.medium.com/KFlwhEH0Pub) - A guide to cost-efficient executor configuration for Apache Spark applications.
- [Spark OOM Error — Closeup](https://link.medium.com/LLX1pap0Pub) - A detailed explanation of Spark's Out of Memory (OOM) error and strategies to address it.
- [3 Reasons Why Spark’s Lazy Evaluation is Useful](https://link.medium.com/faI3jfc0Pub) - An exploration of the benefits of Spark's lazy evaluation mechanism.
